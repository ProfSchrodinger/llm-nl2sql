{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f5647f0-7391-42e5-adf4-f769356d4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import sqlite3\n",
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "038ab5c6-ad77-44a6-a466-1e0ce88073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_DIR = 'data/evaluation'\n",
    "TEST_FILE = os.path.join(DATABASE_DIR, 'test_spider.json')\n",
    "MODEL_PATH = 'model/best_model.pt'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6bb9022-47a7-4aa4-9058-defcc743719e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded fine-tuned model from model/best_model.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    print(f\"Loaded fine-tuned model from {MODEL_PATH}\")\n",
    "else:\n",
    "    print(f\"Fine-tuned model not found at {MODEL_PATH}. Using base model.\")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f012704-8ac9-445c-9252-d378563a488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer('BAAI/bge-small-en-v1.5', device=device)\n",
    "embedding_size = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ca0c94-f17c-44d7-a309-d4a9687dfb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_schema(db_path, db_id):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = [table[0] for table in cursor.fetchall()]\n",
    "    \n",
    "    table_schema_text = []\n",
    "    \n",
    "    for table in tables:\n",
    "        cursor.execute(f\"PRAGMA table_info({table});\")\n",
    "        columns_info = cursor.fetchall()\n",
    "        \n",
    "        primary_keys = [col[1] for col in columns_info if col[5] > 0]\n",
    "        \n",
    "        cursor.execute(f\"PRAGMA foreign_key_list({table});\")\n",
    "        foreign_keys = cursor.fetchall()\n",
    "        \n",
    "        columns = []\n",
    "        for col in columns_info:\n",
    "            col_name = col[1]\n",
    "            col_type = col[2].lower()\n",
    "            \n",
    "            pk_marker = \" [PK]\" if col_name in primary_keys else \"\"\n",
    "\n",
    "            fk_info = \"\"\n",
    "            for fk in foreign_keys:\n",
    "                if col_name == fk[3]:\n",
    "                    fk_table = fk[2]\n",
    "                    fk_col = fk[4]\n",
    "                    fk_info = f\" [FK -> {fk_table}.{fk_col}]\"\n",
    "                    break\n",
    "            \n",
    "            columns.append(f\"{col_name} ({col_type}){pk_marker}{fk_info}\")\n",
    "        \n",
    "        if columns:\n",
    "            cols_text = \", \".join(columns)\n",
    "            table_schema_text.append(f\"Table: {table} ({cols_text})\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    schema_text = \"\\n\".join(table_schema_text)\n",
    "    return schema_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "706f9b51-c732-41b0-9ce8-918981ae8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "db_ids = []\n",
    "schema_texts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d6214bf-b358-42a8-a735-d0d34349efb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing database: restaurants\n",
      "Processing database: yelp\n",
      "Processing database: geo\n",
      "Processing database: academic\n",
      "Processing database: imdb\n",
      "Processing database: scholar\n",
      "Indexed 6 databases: restaurants, yelp, geo, academic, imdb, scholar\n"
     ]
    }
   ],
   "source": [
    "for db_folder in os.listdir(DATABASE_DIR):\n",
    "    db_path = os.path.join(DATABASE_DIR, db_folder, f\"{db_folder}.sqlite\")\n",
    "    \n",
    "    if os.path.exists(db_path):\n",
    "        print(f\"Processing database: {db_folder}\")\n",
    "\n",
    "        schema_text = extract_schema(db_path, db_folder)\n",
    "        schema_texts[db_folder] = schema_text\n",
    "\n",
    "        embedding = embedding_model.encode([schema_text])[0]\n",
    "        embedding = np.array([embedding]).astype('float32')\n",
    "\n",
    "        index.add(embedding)\n",
    "        db_ids.append(db_folder)\n",
    "\n",
    "print(f\"Indexed {len(db_ids)} databases: {', '.join(db_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26595a27-d022-4f23-a930-9164ef05e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(sql_query, db_path):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql_query)\n",
    "        results = cursor.fetchall()\n",
    "        conn.close()\n",
    "        return True, results\n",
    "    except Exception as e:\n",
    "        return False, str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aca2e4bb-e339-4f33-b5e7-be2dbc61427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_schema(question):\n",
    "    if len(db_ids) == 0:\n",
    "        return None\n",
    "\n",
    "    question_embedding = embedding_model.encode([question])[0]\n",
    "    question_embedding = np.array([question_embedding]).astype('float32')\n",
    "\n",
    "    D, I = index.search(question_embedding, 1)\n",
    "    \n",
    "    if I[0][0] < len(db_ids):\n",
    "        return db_ids[I[0][0]]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c94a41f-535a-4fbf-a785-72155aec08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql(question, db_id=None):\n",
    "    if db_id is None:\n",
    "        db_id = find_most_similar_schema(question)\n",
    "        if db_id is None:\n",
    "            return \"No database found\", None, \"\"\n",
    "    \n",
    "    schema_text = schema_texts.get(db_id)\n",
    "    if schema_text is None:\n",
    "        return f\"Database '{db_id}' not found\", db_id, \"\"\n",
    "    \n",
    "    input_text = f\"translate to SQL: {question} \\n{schema_text}\"\n",
    "    \n",
    "    input_ids = tokenizer(\n",
    "        input_text,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=128,\n",
    "            num_beams=5,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    sql_query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return sql_query, db_id, input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6cb79ba-8543-4b19-934f-d0b6fda842ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1659 test examples.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(TEST_FILE):\n",
    "    print(f\"Error: Test file {TEST_FILE} not found.\")\n",
    "else:\n",
    "    with open(TEST_FILE, 'r') as f:\n",
    "        temp_test_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(temp_test_data)} test examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c1810aa-8c15-452b-9681-ae9872311642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['restaurants', 'yelp', 'geo', 'academic', 'imdb', 'scholar']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_dirs = [d for d in os.listdir(DATABASE_DIR) if os.path.isdir(os.path.join(DATABASE_DIR, d))]\n",
    "db_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cca6f8d-db5b-4e90-965b-fc385740fda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1659 test examples.\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "\n",
    "for each in temp_test_data:\n",
    "    if each['db_id'] in db_dirs:\n",
    "        test_data.append(each)\n",
    "\n",
    "print(f\"Loaded {len(test_data)} test examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8bd5dc-118f-46e9-a8aa-213672238f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sql(sql):\n",
    "    sql = re.sub(r\"\\s+\", \" \", sql).strip().lower()\n",
    "    # Ensure operators are separated by a space\n",
    "    sql = re.sub(r\"(=|<=|>=|<>|<|>)\", lambda m: f\" {m.group(0)} \", sql)\n",
    "    sql = re.sub(r\"\\s+\", \" \", sql).strip()\n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9344e13b-7597-47dc-ac6f-0314a6bb5a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3d33e03-c635-47de-9398-ca34a144a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match = 0\n",
    "execution_match = 0\n",
    "execution_true = 0\n",
    "simple_count = 0\n",
    "simple_exact_match = 0\n",
    "simple_execution_match = 0\n",
    "complex_count = 0\n",
    "complex_exact_match = 0\n",
    "complex_execution_match = 0\n",
    "rag_correct_db = 0\n",
    "\n",
    "total = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e18bf5-6cef-4a1e-9e18-fe2df6e6812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in tqdm(test_data, desc=\"Evaluating\"):\n",
    "    question = example['question']\n",
    "    true_db_id = example['db_id']\n",
    "    true_sql = example['query']\n",
    "    \n",
    "    if true_db_id not in db_ids:\n",
    "        print(f\"Warning: Database '{true_db_id}' not in index. Skipping example.\")\n",
    "        continue\n",
    "\n",
    "    pred_sql, pred_db_id, _ = generate_sql(question)\n",
    "\n",
    "    if pred_db_id == true_db_id:\n",
    "        rag_correct_db += 1\n",
    "\n",
    "    if re.search(r'\\bjoin\\b', true_sql, re.IGNORECASE):\n",
    "        complex_query = True\n",
    "        complex_count += 1\n",
    "    else:\n",
    "        complex_query = False\n",
    "        simple_count += 1\n",
    "\n",
    "    if normalize_sql(pred_sql) == normalize_sql(true_sql):\n",
    "        exact_match += 1\n",
    "        if complex_query:\n",
    "            complex_exact_match += 1\n",
    "        else:\n",
    "            simple_exact_match += 1\n",
    "\n",
    "    db_path = os.path.join(DATABASE_DIR, true_db_id, f\"{true_db_id}.sqlite\")\n",
    "    \n",
    "    _, true_results = execute_sql(true_sql, db_path)\n",
    "    pred_ok, pred_results = execute_sql(pred_sql, db_path)\n",
    "\n",
    "    if pred_ok:\n",
    "        execution_true += 1\n",
    "\n",
    "        if pred_results == true_results:\n",
    "            execution_match += 1\n",
    "            if complex_query:\n",
    "                complex_execution_match += 1\n",
    "            else:\n",
    "                simple_execution_match += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05547df-adfb-4bb9-809c-25db1c4fcc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_div(n, d):\n",
    "    return n / d if d else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd12fd-67ea-415a-b5d0-0fdb56a0a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match_acc = safe_div(exact_match, total)\n",
    "execution_acc = safe_div(execution_match, total)\n",
    "execution_true_acc = safe_div(execution_true, total)\n",
    "simple_exact_acc = safe_div(simple_exact_match, simple_count)\n",
    "simple_exec_acc = safe_div(simple_execution_match, simple_count)\n",
    "complex_exact_acc = safe_div(complex_exact_match, complex_count)\n",
    "complex_exec_acc = safe_div(complex_execution_match, complex_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db4b7e-d608-4419-aa99-867081761eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Examples: {total}\")\n",
    "print(f\"RAG DB Identification Accuracy: {rag_acc:.4f} ({rag_correct_db}/{total})\\n\")\n",
    "print(f\"Exact Match Accuracy:      {exact_match_acc:.4f}\")\n",
    "print(f\"Execution Match Accuracy:  {execution_acc:.4f}\")\n",
    "print(f\"Execution True Accuracy:   {execution_true_acc:.4f}\\n\")\n",
    "print(f\"Simple Count:              {simple_count}\")\n",
    "print(f\"  • Simple Exact Match:    {simple_exact_acc:.4f}\")\n",
    "print(f\"  • Simple Exec  Match:    {simple_exec_acc:.4f}\")\n",
    "print(f\"Complex Count:             {complex_count}\")\n",
    "print(f\"  • Complex Exact Match:   {complex_exact_acc:.4f}\")\n",
    "print(f\"  • Complex Exec  Match:   {complex_exec_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llmcourse)",
   "language": "python",
   "name": "llmcourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
